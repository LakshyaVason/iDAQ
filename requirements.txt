# LLM and local inference
ollama  # âœ… REQUIRED for calling local Ollama models

# Remove transformers if not needed for generation/embedding
# If still needed (e.g. OpenAI API, tokenizer etc), pin to stable:
transformers==4.34.1
accelerate>=0.33.0
sentencepiece
protobuf
safetensors
python-dotenv>=1.0.0

# ML + analytics
pandas
scikit-learn
joblib
numpy

# LangChain ecosystem
requests
# LangChain stack
langchain
langserve[all]
fastapi
uvicorn
langchain-community
